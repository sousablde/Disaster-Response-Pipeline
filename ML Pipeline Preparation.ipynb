{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///messages.db')\n",
    "df = pd.read_sql_table(\"messages\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on this quick check most of the data is very imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"message\"]\n",
    "y = df.drop(['message', 'genre', 'id', 'original'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    Receives text related data and processes it\n",
    "    Args: text related data (columns)\n",
    "    Returns: tokenized text\n",
    "    '''\n",
    "    # get list of all urls using regex\n",
    "    detected_urls = re.findall(url_regex, text) \n",
    "    \n",
    "    # replace each url in text string with placeholder\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # initiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # iterate through each token\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        \n",
    "        # lemmatize, normalize case, and remove leading/trailing white space\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_tester(X, y):\n",
    "    '''\n",
    "    Function to create list of fitted models\n",
    "    Args: training data X and y\n",
    "    returns: list of the selected fitted models\n",
    "    '''\n",
    "    pipe_1 = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "    \n",
    "    pipe_2 = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(ExtraTreesClassifier()))\n",
    "    ])\n",
    "    \n",
    "    pipe_3 = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(GradientBoostingClassifier()))\n",
    "    ])\n",
    "    \n",
    "    pipe_4 = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n",
    "    \n",
    "    pipe_5 = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(SVC()))\n",
    "    ])\n",
    "    \n",
    "    pips = [pipe_1, pipe_2, pipe_3, pipe_4, pipe_5]\n",
    "    pip_names = ['RandomForestClassifier', 'ExtraTreesClassifier', 'GradientBoostingClassifier', \n",
    "                 'AdaBoostClassifier', 'SVC']\n",
    "    \n",
    "    model_fits = []\n",
    "    for i in range(len(pips)):\n",
    "        print('Model: ', pip_names[i])\n",
    "        print(pips[i].get_params())\n",
    "        mdl = pips[i].fit(X, y)\n",
    "        model_fits.append(mdl)\n",
    "        \n",
    "    return model_fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_mdls = multi_tester(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your models\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = y_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_report(model, X_test, y_test):\n",
    "    '''\n",
    "    Function to return model classification reports\n",
    "    Input: Model list, and test data \n",
    "    Output: Prints the Classification report\n",
    "    '''\n",
    "    pip_names = ['RandomForestClassifier', 'ExtraTreesClassifier', 'GradientBoostingClassifier', \n",
    "             'AdaBoostClassifier', 'SVC']\n",
    "    \n",
    "    for i in range(len(model)):\n",
    "        print('______________________________Model______________________________')\n",
    "        print('______________________________', pip_names[i], '______________________________')\n",
    "        y_pred = model[i].predict(X_test)\n",
    "        print(classification_report(y_test, y_pred, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_report(fitted_mdls, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-shops has very little label diversity so it became an edge case, I will drop it for the optimization\n",
    "\n",
    "______________________________ RandomForestClassifier ______________________________\n",
    "\n",
    "\n",
    "                           precision    recall  f1-score   support\n",
    "                           \n",
    "                           \n",
    "             micro avg       0.80      0.44      0.57     27308\n",
    "             \n",
    "             \n",
    "             macro avg       0.58      0.16      0.21     27308\n",
    "             \n",
    "             \n",
    "          weighted avg       0.74      0.44      0.50     27308\n",
    "          \n",
    "          \n",
    "           samples avg       0.65      0.42      0.46     27308\n",
    "           \n",
    "\n",
    "______________________________ ExtraTreesClassifier ______________________________\n",
    "\n",
    "\n",
    "             micro avg       0.79      0.44      0.56     27308\n",
    "             \n",
    "             \n",
    "             macro avg       0.53      0.15      0.21     27308\n",
    "             \n",
    "             \n",
    "          weighted avg       0.71      0.44      0.49     27308\n",
    "          \n",
    "          \n",
    "           samples avg       0.66      0.42      0.46     27308\n",
    "\n",
    "______________________________ GradientBoostingClassifier ______________________________\n",
    "\n",
    "\n",
    "             micro avg       0.76      0.57      0.65     27308\n",
    "             \n",
    "             \n",
    "             macro avg       0.51      0.32      0.38     27308\n",
    "             \n",
    "             \n",
    "          weighted avg       0.72      0.57      0.61     27308\n",
    "          \n",
    "          \n",
    "           samples avg       0.65      0.50      0.52     27308\n",
    "           \n",
    "           \n",
    "______________________________ AdaBoostClassifier ______________________________\n",
    "\n",
    "\n",
    "             micro avg       0.77      0.58      0.66     27308\n",
    "             \n",
    "             \n",
    "             macro avg       0.58      0.33      0.40     27308\n",
    "             \n",
    "             \n",
    "          weighted avg       0.73      0.58      0.62     27308\n",
    "          \n",
    "          \n",
    "           samples avg       0.63      0.50      0.51     27308\n",
    "           \n",
    "______________________________ SVC ______________________________\n",
    "\n",
    "\n",
    "             micro avg       0.76      0.24      0.36     27308\n",
    "             \n",
    "             \n",
    "             macro avg       0.02      0.03      0.02     27308\n",
    "             \n",
    "             \n",
    "          weighted avg       0.18      0.24      0.21     27308\n",
    "          \n",
    "          \n",
    "           samples avg       0.76      0.32      0.40     27308\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve models based on poor target performance elimination\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each.\n",
    "Testing models after dropping poor predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the targets that had the word performances based on the classification report\n",
    "targs_drop = ['offer', 'security', 'infrastructure_related', 'tools', \n",
    "              'hospitals', 'shops', 'aid_centers', 'other_infrastructure', 'fire', 'other_weather']\n",
    "y_min = y.copy()\n",
    "y_min.drop(targs_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_min, random_state = 42, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_mdls_min = multi_tester(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = y_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_report(fitted_mdls_min, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "______________________________ RandomForestClassifier ______________________________\n",
    "\n",
    "                           precision    recall  f1-score   support \n",
    "                           \n",
    "              micro avg       0.80      0.48      0.60     25330\n",
    "              \n",
    "              macro avg       0.72      0.22      0.30     25330\n",
    "              \n",
    "           weighted avg       0.78      0.48      0.53     25330\n",
    "           \n",
    "            samples avg       0.66      0.44      0.48     25330\n",
    "\n",
    "______________________________ ExtraTreesClassifier ______________________________\n",
    "\n",
    "        micro avg       0.79      0.46      0.59     25330\n",
    "        \n",
    "        macro avg       0.68      0.20      0.27     25330\n",
    "        \n",
    "     weighted avg       0.75      0.46      0.52     25330\n",
    "     \n",
    "      samples avg       0.65      0.43      0.47     25330    \n",
    "\n",
    "______________________________ GradientBoostingClassifier ______________________________\n",
    "\n",
    "        micro avg       0.78      0.61      0.68     25330\n",
    "        \n",
    "        macro avg       0.65      0.43      0.50     25330\n",
    "        \n",
    "     weighted avg       0.76      0.61      0.65     25330\n",
    "     \n",
    "      samples avg       0.66      0.52      0.54     25330\n",
    "           \n",
    "           \n",
    "______________________________ AdaBoostClassifier ______________________________\n",
    "\n",
    "        micro avg       0.77      0.61      0.69     25330\n",
    "        \n",
    "        macro avg       0.69      0.42      0.51     25330\n",
    "        \n",
    "     weighted avg       0.75      0.61      0.66     25330\n",
    "     \n",
    "      samples avg       0.64      0.51      0.53     25330\n",
    "           \n",
    "______________________________ SVC ______________________________\n",
    "\n",
    "        micro avg       0.76      0.26      0.38     25330\n",
    "        \n",
    "        macro avg       0.03      0.04      0.03     25330\n",
    "        \n",
    "     weighted avg       0.19      0.26      0.22     25330\n",
    "     \n",
    "      samples avg       0.76      0.33      0.41     25330\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Improve your model\n",
    "Use grid search to find better parameters. \n",
    "\n",
    "I will work on my best performing model adaboost and using the reduced target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'tfidf__use_idf': (True, False),\n",
    "              'clf__estimator__n_estimators': [50, 100], \n",
    "              'clf__estimator__random_state': [42],\n",
    "             'clf__estimator__learning_rate': [0.5]} \n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters, cv = 10,\n",
    "                  refit = True, verbose = 1, return_train_score = True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the targets that had the word performances based on the classification report\n",
    "targs_drop = ['offer', 'security', 'infrastructure_related', 'tools', \n",
    "              'hospitals', 'shops', 'aid_centers', 'other_infrastructure', 'fire', 'other_weather']\n",
    "y_min = y.copy()\n",
    "y_min.drop(targs_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_min, random_state = 42, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ada = cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best model :', best_ada.best_score_)\n",
    "print('Params :', best_ada.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_ada.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Other Approaches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom estimators (inspired by: [repo](https://github.com/hnbezz/Portfolio_under_construction/blob/master/Disaster_Response_Pipeline/ML%20Pipeline%20Preparation.ipynb) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "    def start_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            if len(pos_tags) != 0:\n",
    "                first_word, first_tag = pos_tags[0]\n",
    "                if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                    return 1\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tag = pd.Series(X).apply(self.start_verb)\n",
    "        return pd.DataFrame(X_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_len(data):\n",
    "    return np.array([len(text) for text in data]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the targets that had the word performances based on the classification report\n",
    "targs_drop = ['offer', 'security', 'infrastructure_related', 'tools', \n",
    "              'hospitals', 'shops', 'aid_centers', 'other_infrastructure', 'fire', 'other_weather', 'other_aid']\n",
    "y_min = y.copy()\n",
    "y_min.drop(targs_drop, axis = 1, inplace = True)\n",
    "target_names = y_min.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratifying data\n",
    "mlss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.33, random_state=42)\n",
    "\n",
    "for train_index, test_index in mlss.split(X, y_min):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_min.values[train_index], y_min.values[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train,columns=target_names)\n",
    "y_test = pd.DataFrame(y_test,columns=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_2 = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('best', TruncatedSVD()),\n",
    "                ('tfidf', TfidfTransformer())])), \n",
    "        ('start_verb', StartVerbExtractor())])), \n",
    "    ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'features__text_pipeline__tfidf__use_idf': (True, False),\n",
    "              'clf__estimator__n_estimators': [100, 200, 300], \n",
    "              'clf__estimator__random_state': [42],\n",
    "             'clf__estimator__learning_rate': [0.05]} \n",
    "\n",
    "cv_2 = GridSearchCV(pipeline, param_grid = parameters, cv = 10,\n",
    "                  refit = True, verbose = 1, return_train_score = True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ada_2 = cv_2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best model :', best_ada_2.best_score_)\n",
    "print('Params :', best_ada_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_ada_2.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = ['there is a storm and people are trapped']\n",
    "test = cv.predict(test_text)\n",
    "print(y_train.columns.values[(test.flatten()==1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a pretty cool prediction, let's try a few more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = ['we are having an earthquake, buildings are destroyed, victims need clothes']\n",
    "test = cv.predict(test_text)\n",
    "print(y_train.columns.values[(test.flatten()==1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = ['there was an accident near the bank and we need an ambulance']\n",
    "test = cv.predict(test_text)\n",
    "print(y_train.columns.values[(test.flatten()==1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv_2, open('disaster_ada.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
